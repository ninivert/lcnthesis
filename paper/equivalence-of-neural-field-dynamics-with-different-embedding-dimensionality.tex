%% NETN Template file

%% Documentclass:
\documentclass[NETN,manuscript]{stjour-new}

%% Or,
%% For production only, need .otf fonts, private MIT logo files,
%% and need to use lualatex:
% \documentclass[finalfonts,NETN]{stjour-new}

%%%%%%%%%%% Article Set-Up %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Article Type:

%% Choose one of these options, (Default is Research).
%% Research
%% Methods 
%% Data
%% Review
%% Perspectives

\articletype{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% author definitions should be placed here:

\def\R{\mathbb R}
\def\RR{\R^2}
\def\Rp{\R^p}
\def\d{\mathrm d}
\def\Jab{\tilde J_{\alpha\beta}}
\def\Fab{\tilde F_{\alpha\beta}}
\def\Gab{\tilde G_{\alpha\beta}}
\def\Jij{J_{ij}}
\def\Fij{F_{ij}}
\def\gij{G_{ij}}
\def\wu{w_\textrm{U}}
\def\hu{h_\textrm{U}}
\def\bO{\mathcal{O}}
\def\CDF{\mathrm{CDF}}
\newcommand{\avg}[1]{\langle{#1}\rangle}
\newcommand{\norm}[1]{\lVert{#1}\rVert}
% \def\avg#1{\langle{#1}\rangle}
\renewcommand{\vec}[1]{\boldsymbol{#1}}


\begin{document}

% TODO: what title is better ?
% \title{Equivalence of neural field dynamics with different embedding dimensionality}
\title{Neural fields with different embedding dimensionality can express identical dynamics}
% \title{Neural dynamics can be equivalently embedded in neural fields of different dimensions}

% \subtitle{<Subtitle Here>} %% Optional subtitle

%% If shortened title for running head is needed so that the article title can fit
%%   in the running head, use [] argument, ie,
%%
%%   \title[Shortened Title for Running Head]{Title of Article}
%%   \subtitle{Subtitle Here}

%%% Author/Affil
%% Since we use \affil{} in the argument of the \author command, we
%% need to supply another version of the author names, without \affil{}
%% to be used for running heads:

\author{Nicole Vadot\affil{1}, Valentin Schmutz\affil{1}, \and Wulfram Gerstner \affil{1}}

\affiliation{1}{LCN, EPFL, Lausanne, Switzerland}

%ie.
%\affiliation{1}{Gatsby Computational Neuroscience Unit, University
%College London, London, United Kingdom} 

% \affiliation{2}{Another Department, Institution, City, Country}

%ie
%\affiliation{2}{Center for Studies in
%Behavioral Neurobiology, Concordia University, Montreal, Quebec,
%Canada}

\correspondingauthor{Nicole Vadot}{nicole.vadot@epfl.ch}
\correspondingauthor{Valentin Schmutz}{valentin.schmutz@epfl.ch}
\correspondingauthor{Wulfram Gerstner}{wulfram.gerstner@epfl.ch}

% ie,
%\correspondingauthor{Ritwik K. Niyogi}{ritwik.niyogi@gatsby.ucl.ac.uk}

\keywords{Neural fields, Embedding, Dimensionality}

%ie
%\keywords{Work, Leisure, Normative, Microscopic,  Reinforcement Learning, Economics}

\begin{abstract}
Classical neural field models describe interactions between neurons positioned in an embedding; often a physical space (for instance, that of the cortical sheet) or, later, abstract spaces (for instance, that of neuron celltypes), in which the dynamics are highly regular in space and time. Recent improvements in recordings of neural activity have shined the light on the smoothness of the neural dynamics, when placed in an appropriate embedding space.

Decoupling the embedding space from the physical position of neurons begs the question of uniqueness of the embedding space. Given an embedding space and neural dynamics theron, are there other embedding spaces which can express the same behavior?

We show that embedding spaces are not unique, and more suprisingly, that we can find multiple embedding spaces in different dimensions, which all model identical neural dynamics.
The core of this work lies in the study of bijective mappings $S$ between $[0,1]^2$ and $[0,1]$, which allows mapping a two-dimensional neural field to an equivalent one-dimensional neural field.
This procedure is easily generalized to map between embeddings in arbitrary number of dimensions.
We introduce a measure of locality, which quantifies how the regularity of the neural fields in conserved through the mappings $S$. This allows us to show that the resulting neural field is well-behaved, and can therefore be approximated using classical grid-based methods.
To illustrate these results through numerical models, we describe a coarse-graining procedure enforcing the locality of the numerically applied mappings.
\end{abstract}

% \begin{authorsummary}
% Author Summary here.
% \end{authorsummary}

\section{Introduction}

% NOTE: the goal here is to give an intuitive understanding of the problem,
% kind of in the same "story-telling"-way that I did in the master thesis.
% This also allows to introduce some of the notation that I use later on.

\subsection{Neural field models in neuroscience}

Early recordings of cats' somatosensory \citep{Mou57} and visual \citep{HubWie62} cortices suggested that the cortical sheet is organized in vertical columns of functionally similar neurons.

The columnar organization of the cortex motivated the design of spatially structured models of neural population dynamics, namely neural field models \citep{WilCow73,Nun74,Ama77}, where the spatial dimensions corresponded to the two dimensions of the cortical sheet. 

As models of spatiotemporal neural population dynamics on the cortical sheet, neural field models can be used to explain experimentally observed patterns of cortical activity, such as travelling waves in visual \citep{SatNau12,MulRey14}, somatosensory \citep{PetHah03,FerBol06}, motor \citep{RubRob06,TakKim15}, and hippocampal \citep{LubSia09,PatFuj12,PatSch13} cortices (see \citep{MulCha18} for a review), and are used to model large-scale brain signals, such as electroencephalography (EEG) recordings \citep{Bre17} (see also \citep{DipRan18} for an example of neural field modelling of calcium imaging recording of the visual cortex).

More recent recording methods, especially in rodents, have provided evidence of low-dimensional organization of neuronal activity that does not depend on the physical locations of neurons on the cortical sheet. For example, contrary to cats' visual cortex, the orientation selectivity of pyramidal neurons in a rat's visual cortex does not depend on their locations, that is, orientation selectivity is heterogeneous at any given location \citep{OhkChu05}. Moreover, the activity of interneurons in any small volume of the visual cortex is also heterogeneous and seems to be structured by a low-dimensional manifold of fine cell subtypes \citep{BugDuf22}. The local functional heterogeneity of neuronal activity in the cortex challenges the old concept of functionally homogeneous cortical columns and, with it, classical neural field models. 

While, historically, the spatial dimensions in neural field models have been the two dimensions of the cortical sheet (with the notable exception of the ring models for orientation selectivity in the visual cortex \citep{BenBar95} and the head-direction system \citep{Zha96}), the "space" in neural field models does not need to represent physical space but can represent any suitable abstract embedding space. Neural field models with abstract embedding spaces could constitute a generalization of classical neural field theory for cortical networks that are not solely structured by distances of neurons on the cortical sheet.

Moreover, this work is motivated by recent mathematical developments \citep{JabPoy21} in mean-field theories involving the theory of graphons. Informally, these results suggest that, as long as the connectivity scales as $1/N$ (where $N$ is the number of neurons), the dynamics of large networks can be described in the $N \to \infty$ limit by a neural field equation where the embedding is simply the interval $[0,1]$. In the following, we will describe a method of explicitly writing such a one-dimensional neural field.

\subsection{Formulating a one-dimensional neural field}

% If we consider neural fields in abstract embedding spaces, which embedding space should we choose? More fundamentally, given some spatiotemporal dynamics, is there a "natural" choice for the embedding space?

% We show that the answer to the second question is highly nontrivial because even the dimensionality of the embedding space, for some given spatiotemporal dynamics, is not clearly defined. This means that it is possible to find two embeddings (each associated with a connectivity kernel) of different dimensions that give rise to identical dynamics.

% TODO: do we talk about the tau=1, R=1 ?
% TODO: do we talk about external currents ?

Let us write a neural field associated with a $p$-dimensional embedding $\Rp$. $h(\vec z, t)$ describes the potential of the neural population at position $\vec z=(z_1,\cdots,z_p)$ in the embedding. The connectivity kernel $w(\vec y, \vec z)$ describes the amplitude of the recurrent currents from the population at $\vec z$ to the population at $\vec y$. $\rho(\vec z)$ measures the number of neurons per unit volume of the embedding space, and we use the notation $\rho(\mathrm d \vec y) := \rho(\vec y) \mathrm d \vec y$ to emphasize that the integral is weighted by the neuron density. The activation function $\phi(h)$ describes the firing rate of a given neuron (population) with potential $h$. The neural field then evolves according to \autoref{eq:nf-in-rp}:  

\begin{equation} \label{eq:nf-in-rp}
\partial_t h(\vec z, t) = \underbrace{-h(\vec z, t)}_\text{exponential decay} + \underbrace{\int_{\mathbb{R}^p} w(\vec z, \vec y) \phi(h(\vec y, t)) \rho(\mathrm d \vec y)}_\text{recurrent current}.
\end{equation}

The embedding space $\Rp$ can be mapped to $[0,1]^p$ via bijective functions between the two spaces. For instance, if the neuron density factorizes as $\rho(z_1, \cdots, z_p)= \rho_1(z_1) \cdots \rho_p(z_p)$, then the associated cumulative density functions can be used to perform a change of variables, resulting in the an equivalent "uniform" neural field equation:

\begin{equation} \label{eq:nf-in-01p}
\partial_t h_U(t, \vec v) = -h_U(t, \vec v) + \int_{[0,1]^p} w_U(\vec v, \vec u) \phi(h_U(t, \vec u)) \mathrm d \vec u.
\end{equation}

If the neuron density does not factorize, then one can arrive at the same formulation by redefining the connectivity kernel to include the neuron density and the determinant of the transformation. [TODO: this sentence might need some work]

In particular for $p=2$, we show that for any two-dimensional neural field equation (that is, with two spatial dimensions), there is a one-dimensional neural field equation, where the embedding space is simply the interval $[0,1]$, from which the solution to the two-dimensional equation can be fully reconstructed. The mapping from the two-dimensional equation to the one-dimensional equation is done via well-known measurable bijections between the square $[0,1]^2$ and the interval $[0,1]$. Importantly, these bijections are not (and can't be, due to Netto's theorem [TODO: citation?]) diffeomorphisms.
% Also, we show that although the connectivity kernel of the one-dimensional equation seems to have a fractal structure, it is sufficiently regular for its solution to be numerically approximated using standard grid-based simulations.
The main idea is to define a measurable bijective mapping $S : [0,1]^2 \mapsto [0,1]$ and a measure $\lambda : [0,1]^2 \mapsto \mathbb{R}^+$, such that we can write a one-dimensional neural field	$\tilde h(\alpha, t)$ with a connectivity kernel defined as $\tilde w(\alpha, \beta) = w_U(S^{-1}(\alpha), S^{-1}(\beta))$. 
The question of well-posedness of the neural field in \autoref{eq:nf-in-01} is defered in \autoref{sec:proof-equivalence}.

\begin{equation} \label{eq:nf-in-01}
\partial_t \tilde h(\alpha, t) = -\tilde h(\alpha, t) + \int_{[0,1]} \tilde w(\alpha, \beta) \phi(\tilde h(\beta, t)) \left[\lambda \circ S^{-1}\right](\d \beta)
\end{equation}

\subsection{Regularity of the mapping}

[chap 1.4] introduce a random mapping to introduce locality

figure 1.2

question of uniqueness, discretization error, mean field limit and locality, link with numerical simualtions. chap 1.4, chap 3.1

"discretization error"

argue over smoothness of the kernel (see presentation given for SPC)


chap 1.1, chap 2.1, 2.5


Our results suggest that the notion of (spatial) dimensionality in neural field dynamics is not well-defined if not associated with a constraint on the regularity of the neural fields (and the connectivity kernel). Thereby, by studying a simple toy model, this work illustrates the importance of the analytic notion of regularity when neural population dynamics over abstract continuous spaces are considered. 

\section{Study of mappings from 2D to 1D}

\subsection{$S$ as the limit of a sequence of mappings}

motivation, why do we do this

\subsection{The Z-mapping and Column mapping}

introduce the mappings and give plots

\subsection{Behavior and locality measures}

measure of locality, give examples applied to the mappings.

see how it scales, and say what we expect

\subsection{Numerical demonstrations}

chap. 2.1, 

we stress that this toy model serves only for illustration purposes, and our results apply to any neural field

introduce coarse-graining procedure (applying the smoothness hypothesis numerically)

introduce the low-rank cycling model

\section{Proof of results}

\subsection{Analytical equivalence given $S$ measurable and bijective}
\label{sec:proof-equivalence}

\subsection{Numerical convergence}

\section{Conclusion}

\acknowledgments

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% End of Article

% \acknowledgments
% \section{Supporting Information} (optional)
% \section{Competing Interests} (optional)
% \bibliography{<name of .bib file>}

% \acknowledgments
% The Funder and award ID information you input at submission will be introduced by the publisher under a Funding Information head during production. 
% Please use this space for any additional acknowledgements and verbiage required by your funders.

% \section{Supporting Information}
% This is an optional section. Please use this space to provide information about any supporting information referred to in your manuscript.

% \section{Competing Interests}
% This is an optional section. If you declared a conflict of interest when you submitted your manuscript, please  use this space to provide details about this conflict.

% \section{Technical Terms}

% All NETN article types require Technical Terms.

% Identify approximately 10 key terms that are mentioned in your article and whose usage and definition may not be familiar across the broad readership of the journal. 
% Provide brief (20-word or less) definitions for each term, avoiding in these definitions the use of jargon, or highly technical or specialized language. 
% When the article is typeset, the Technical Terms will appear in the margins at or near their first mention in the text.

% In your manuscript, bold the first occurrence of each \textbf{Technical Term} and then provide a list of the terms and their definitions at the end of the manuscript after the references. 

%%%%%%%%%%%%%%%%%%%%%%%
%% The bibliography

%% The bibliography is made using only the entries that you cite using 
%% \cite{}, or one of the Natbib citation entries, like \citep{}, \citet{} etc.

\bibliography{references}

%ie.,
%\bibliography{bibsamp}

% \section{Technical Terms}

% \textbf{Technical Term} a key term that is mentioned in an NETN article and whose usage and definition may not be familiar across the broad readership of the journal. 

% \textbf{Technical Term} a key term that is mentioned in an NETN article and whose usage and definition may not be familiar across the broad readership of the journal. 

% \textbf{Technical Term} a key term that is mentioned in an NETN article and whose usage and definition may not be familiar across the broad readership of the journal. 

% \textbf{Technical Term} a key term that is mentioned in an NETN article and whose usage and definition may not be familiar across the broad readership of the journal. 

\end{document}

% The examples below may be helpful when you are looking
% for a quick example. They are taken from NETNsample.tex
% so you can see their results in NETNSample.pdf

% \begin{boxedtext}{box title}
% Text
% \end{boxedtext}

% or, put figure in boxed text:
% \begin{boxedtext}{box title}
% Text
% \begin{figure}
% illustration
% \caption{caption here}
% \end{figure}
% \end{boxedtext}

% or, put table in boxed text:
% \begin{boxedtext}{box title}
% Text
% \begin{table}
% \caption{caption here}
% tabular...
% \end{table}
% \end{boxedtext}

% or, put anything in whitebox within boxed text:
% \begin{boxedtext}{Showing the use of whitebox} 
% Going beyond the examination of shared topological features across..

% \whitebox{
% From $\mathcal{W}$, we can estimate the variability in the fluctuations of the functional connection between nodes $i$ and $j$ over time as:
% \begin{equation}
% s_{ij}=\sqrt{\frac{1}{T-L}\sum_{t=1}^{T-L+1}(W_{ij}(t) - m_{ij})}
% \end{equation}
% where $m_{ij}=\frac{1}{T-L+1}\sum_{t=1}^{T-L+1}W_{ij}(t)$ is the mean
% dynamic functional connectivity over time. 
% }
% ...differences across a range of network classes.
% \end{boxedtext}

% ==================
% More samples:

% \section{Sample Section}
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.

% \subsection{Sample Subsection}
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.

% \subsubsection{Sample Subsubsection}
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.
% Text here. Text here. Text here. Text here.

% \section{Sample equations}
% \begin{equation}
% \label{eq:rhoCHT}
% \rho^{\pi}= \frac{RI + \mathbb{E}_{\pi([L,\tau_L]|\textrm{post})}
% \left[C_L(\taupav+\tau_L) \right]   +
% \displaystyle{\int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}
% \Biggl[\/\sum_{n_{L|[\textrm{pre},w]}}C_L(\tau_L)
% \Biggr]            }      {P +
% \mathbb{E}_{\pi([L,\tau_L] |\textrm{post})}[\tau_{L}] +\taupav +
% \displaystyle{ \int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}   
% \Biggl[\sum_{n_{L|[\textrm{pre},w]}}\tau_L\Biggr]  
% }
% \end{equation}
% As long as
% $RI - K_LP > 
% \frac{1}{\beta}$
% \begin{equation}
% %\def\theequation{5.1}
% \left.\begin{array}{lrcl}
% &\rho^{\pi} &=&  \displaystyle\frac{\beta ( RI + K_L \taupav )-1} {\beta
% (P+\taupav )}    \\[12pt]
% \hbox{and}\hbox to .25in{\hfill}&\mathbb{E}[\tau_L | \text{post}] &=&\displaystyle \frac{P+\taupav}{\beta ( RI -
% K_LP)-1}  
% \label{eq:analytical_linear}
% \end{array}\right\}\hbox to 1.25in{\hfill}
% \end{equation} 

% \subsection{Simple code sample}

% \begin{code}
% \begin{verbatim}
% procedure bubbleSort( A : list of sortable items )
%     n = length(A)
%     repeat
%        newn = 0
%        for i = 1 to n-1 inclusive do
%           if A[i-1] > A[i] then
%              swap(A[i-1], A[i])
%              newn = i
%           end if
%        end for
%        n = newn
%     until n = 0
% end procedure
% \end{verbatim}
% \end{code}

% \subsection{Algorithm environment}

% %% \begin{algorithm} takes option [p][b][t][h],  or some combination, like \begin{figure}
% %% See documentation for algorithmic.sty for more information on formatting algorithms.

% \begin{algorithm}[h]
% \caption{A sample in an algorithm environment.}
% \begin{algorithmic}
% \If {$i\geq maxval$}
%     \State $i\gets 0$
% \Else
%     \If {$i+k\leq maxval$}
%         \State $i\gets i+k$
%     \EndIf
% \EndIf
% \end{algorithmic}
% \end{algorithm}


% \section{Technical Terms}
% If you've been asked by the journal editor to provide technical terms and definitions, please bold the first occurrence of each term in the text and provide a list of the terms and their definitions at the end of the manuscript after the references. Please only supply technical terms if you've been instructed to do so by a journal editor.


% \section{Itemized Lists}

% \subsection{Roman list:}

% \begin{enumerate}
% \item[(i)] at high 
% payoffs, subjects work almost continuously, engaging in little leisure
% in between work bouts; 
% \item[(ii)] at low payoffs, they 
% engage in leisure all at once, in long bouts after working, rather
% than distributing the same amount of leisure time into multiple short
% leisure bouts; 
% \item[(iii)] subjects work continuously for the entire price duration, as long as
% the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
% \item[(iv)] the duration of leisure bouts is variable.
% \end{enumerate}

% \subsection{Numbered list:}

% \begin{enumerate}
% \item at high 
% payoffs, subjects work almost continuously, engaging in little leisure
% inbetween work bouts; 
% \item at low payoffs, they 
% engage in leisure all at once, in long bouts after working, rather
% than distributing the same amount of leisure time into multiple short
% leisure bouts; 
% \item subjects work continuously for the entire price duration, as long as
% the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
% \item the duration of leisure bouts is variable.
% \end{enumerate}


% \subsection{Bulleted list:}

% \begin{itemize}
% \item at high 
% payoffs, subjects work almost continuously, engaging in little leisure
% inbetween work bouts; 
% \item at low payoffs, they 
% engage in leisure all at once, in long bouts after working, rather
% than distributing the same amount of leisure time into multiple short
% leisure bouts; 
% \item subjects work continuously for the entire price duration, as long as
% the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
% \item the duration of leisure bouts is variable.
% \end{itemize}

% \section{Natbib citation mark up}

% \subsection{Single citations}
% \noindent
% \begin{tabular}{ll}
% \bf Type&\bf Results\\
% \hline
% \verb+\citet{jon90}+&Jones et al. (1990)\\
% \verb+\citet[chap. 2]{jon90}+&Jones et al. (1990, chap. 2)\\
%     \verb+\citep{jon90}+	    &   	(Jones et al., 1990)\\
%     \verb+\citep[chap. 2]{jon90}+ 	&    	(Jones et al., 1990, chap. 2)\\
%     \verb+\citep[see][]{jon90}+ 	 &    	(see Jones et al., 1990)\\
%     \verb+\citep[see][chap. 2]{jon90}+ 	&    	(see Jones et al., 1990, chap. 2)\\
%     \verb+\citet*{jon90}+ 	    &    	Jones, Baker, and Williams (1990)\\
%     \verb+\citep*{jon90}+	    &    	(Jones, Baker, and Williams,
%     1990) \\
% \end{tabular}

% For example, here are some sample citations:
% citet:\citet{anderson}, citep:\citep{antibayes}, and
% cite*: \citet*{anderson}.

% \subsection{Multiple citations}
% Multiple citations may be made by including more than one citation
% key in the \verb+\cite+ command argument.

% \noindent
% \begin{tabular}{ll}
% \bf Type&\bf Results\\
% \hline
% \verb+\citet{jon90,jam91}+&Jones et al. (1990); James et al. (1991)\\
% \verb+\citep{jon90,jam91}+&(Jones et al., 1990; James et al. 1991)\\
% \verb+\citep{jon90,jon91}+&(Jones et al., 1990, 1991)\\
% \verb+\citep{jon90a,jon90b}+&(Jones et al., 1990a,b)\\
% \end{tabular}

% For example, multiple citations from the CompPsychSample bibliography:
% citet:\citet{anderson,antibayes}, citep:\citep{anderson,antibayes}.
% As you see, the citations are automatically hyperlinked to their
% reference in the bibliography.

% \newpage

% \section{Sample figures}

% \begin{figure}[h] 
% \centerline{\includegraphics[width=\textwidth]{Fig1}}
% \caption{(Colour online) \textbf{Task and key features of the
%  data.} \\
%  A) Cumulative handling time (CHT) task. Grey bars denote work
% (depressing a lever), white gaps show leisure. The subject must
%  accumulate work up to a total period of time called the
% \emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
% intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
% $2$s each time the price is attained, during which the lever is retracted so it cannot
% work; not shown).
% }
% \label{fig:task_data}
% \end{figure}

% \begin{figure}[ht] 
% \widefigure{\fullpagewidth}{Fig1}
% \caption{(Colour online) \textbf{Task and key features of the
%  data.} \\
% A) Cumulative handling time (CHT) task. Grey bars denote work
% (depressing a lever), white gaps show leisure. The subject must
% accumulate work up to a total period of time called the
% \emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
% intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
% $2$s each time the price is attained, during which the lever is retracted so it cannot
% work; not shown).
% }
% \label{newfig:task_data}
% \end{figure}

% \clearpage
% \section{Sample tables}

% \begin{table}[!ht]
% \caption{Time of the Transition Between Phase 1 and Phase 2$^{a}$}
% \label{tab:label}
% \centering
% \begin{tabular}{lc}
% \hline
%  Run  & Time (min)  \\
% \hline
%   $l1$  & 260   \\
%   $l2$  & 300   \\
%   $l3$  & 340   \\
%   $h1$  & 270   \\
%   $h2$  & 250   \\
%   $h3$  & 380   \\
%   $r1$  & 370   \\
%   $r2$  & 390   \\
% \hline
% \multicolumn{2}{l}{$^{a}$Table note text here.}
% \end{tabular}
% \end{table}

% \begin{table}[ht]
% \widecaption{Sample table taken from [treu03]\label{tbl-1}}
% \begin{widetable}
% \advance\tabcolsep-1pt
% \small
% \begin{tabular}{ccrrccccccccc}
% \hline
% \bf 
% POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
% &\multicolumn1c{\bf Y} &\bf
% RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
% IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
% IAP2 &\bf star &\bf E &\bf Comment\\
% \hline
% 0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
% 21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
% 0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
% 0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
% 0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
% 0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
% 0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
% 0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
% 0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
% 22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
% edge \\
% \hline
% \multicolumn{13}{l}{%
% Table 2 is published in its entirety in the electronic
% edition of the {\it Astrophysical Journal}.}\\[3pt]
% \multicolumn{13}{l}{%
% $^a$ Sample footnote for table 2.}\\[3pt]
% \multicolumn{13}{l}{%
% $^b$ Another sample footnote for table 2.}
% \end{tabular}
% \end{widetable}
% \end{table}

% \begin{table}[p]
% \rotatebox{90}{\vbox{\hsize=\textheight
% \caption{Here is a caption for a table that is found in landscape
% mode.}
% \begin{tabular}{ccrrccccccccc}
% \hline
% \bf 
% POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
% &\multicolumn1c{\bf Y} &\bf
% RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
% IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
% IAP2 &\bf star &\bf E &\bf Comment\\
% \hline
% 0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
% 21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
% 0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
% 0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
% 0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
% 0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
% 0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
% 0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
% 0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
% 22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
% edge \\
% \hline
% \multicolumn{13}{l}{%
% Table 2 is published in its entirety in the electronic
% edition of the {\it Astrophysical Journal}.}\\[3pt]
% \multicolumn{13}{l}{%
% $^a$ Sample footnote for table 2.}\\[3pt]
% \multicolumn{13}{l}{%
% $^b$ Another sample footnote for table 2.}
% \end{tabular}
% }}
% \end{table}
% \clearpage


% \vglue 3in
% Example of table continuing over pages:


% \begin{center}
% \begin{longtable}{ccc@{}}
% \caption{ApJ costs from 1991 to 2013
% \label{tab:table}} \\[2pt]
% \hline
% \bf Year & \bf Subscription & \bf Publication \\
%  & \bf cost &\bf charges\\
%  & \bf(\$) & \bf (\$/page)\\
% \hline
% \endfirsthead

% \multicolumn3c{Table \thetable, \it continued from previous page.}\\[6pt]
% \multicolumn3c{ApJ costs from 1991 to 2013}\\[2pt]
% \hline
% \bf Year & \bf Subscription & \bf Publication \\
%  & \bf cost &\bf charges\\
%  & \bf(\$) & \bf (\$/page)\\
% \hline
% \endhead
% \\\hline
% \\[-8pt]
% \multicolumn{3}{r}{\it Table continued on next page}\\ 
% \endfoot

% \hline
% \endlastfoot

% 1991 & 600 & 100 \\
% 1992 & 650 & 105 \\
% 1993 & 550 & 103 \\
% 1994 & 450 & 110 \\
% 1995 & 410 & 112 \\
% 1996 & 400 & 114 \\
% 1997 & 525 & 115 \\
% 1998 & 590 & 116 \\
% 1999 & 575 & 115 \\
% 2000 & 450 & 103 \\
% 2001 & 490 &  90 \\
% 2002 & 500 &  88 \\
% 2003 & 450 &  90 \\
% 2004 & 460 &  88 \\
% 2005 & 440 &  79 \\
% 2006 & 350 &  77 \\
% 2007 & 325 &  70 \\
% 2008 & 320 &  65 \\
% 2009 & 190 &  68 \\
% 2010 & 280 &  70 \\
% 2011 & 275 &  68 \\
% 2012 & 150 &  56 \\
% 2013 & 140 &  55 \\
% \end{longtable}
% \end{center}

% %%%%%%%%%%%%%%%%%%%%%%%
% %% The bibliography

% %% The bibliography is made using only
% %% the entries that you cite using \cite{}, or one of the Natbib citation
% %% entries, like \citep{}, \citet{} etc.

% \bibliography{bibsamp}

% NO APPENDICES allowed in the Network Neuroscience Style.

% Please submit Supporting Information documents as PDFs in a format ready to publish.
